

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/Blogs/warhammer.png">
  <link rel="icon" href="/Blogs/warhammer.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="唐浩天">
  <meta name="keywords" content="">
  
    <meta name="description" content="什么是 Ajax？Ajax，全称为 Asynchronous JavaScript and XML，即异步的 JavaScript 和 XML。它不是一门编程语言，而是利用 JavaScript 在保证页面不被刷新、页面链接不改变的情况下与服务器交换数据并更新部分网页的技术。 对于传统的网页，如果想更新其内容，那么必须刷新整个页面，但有了 Ajax，便可以在页面不被全部刷新的情况下更新其内容。在这">
<meta property="og:type" content="article">
<meta property="og:title" content="Ajax内容爬取">
<meta property="og:url" content="http://mavericreate.top/Blogs/2025/08/28/Ajax%E5%86%85%E5%AE%B9%E7%88%AC%E5%8F%96/index.html">
<meta property="og:site_name" content="Mavericreate.Blog">
<meta property="og:description" content="什么是 Ajax？Ajax，全称为 Asynchronous JavaScript and XML，即异步的 JavaScript 和 XML。它不是一门编程语言，而是利用 JavaScript 在保证页面不被刷新、页面链接不改变的情况下与服务器交换数据并更新部分网页的技术。 对于传统的网页，如果想更新其内容，那么必须刷新整个页面，但有了 Ajax，便可以在页面不被全部刷新的情况下更新其内容。在这">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.cuiqingcai.com/2jqaq.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/7040b.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/1kiqe.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/t4hm0.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/kah0s.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/l1z1j.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/yfn4s.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/0xqyh.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/3gv1x.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/add5o.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/lyy4e.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/y712p.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/p2u8d.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/dpns6.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/x22b1.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/1ro2i.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/0ldhk.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/tuum6.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/y1o4n.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/bzc8x.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/imum3.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/ammal.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/y6w4q.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/fu94j.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/lwmpo.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/7650u.jpg">
<meta property="og:image" content="https://cdn.cuiqingcai.com/z8xjy.jpg">
<meta property="og:image" content="https://cdn.cuiqingcai.com/l13mw.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/tywxa.png">
<meta property="og:image" content="https://cdn.cuiqingcai.com/8h0oa.png">
<meta property="article:published_time" content="2025-08-28T07:00:00.000Z">
<meta property="article:modified_time" content="2025-08-28T13:30:31.899Z">
<meta property="article:author" content="唐浩天">
<meta property="article:tag" content="Ajax内容爬取">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.cuiqingcai.com/2jqaq.png">
  
  
  
  <title>Ajax内容爬取 - Mavericreate.Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/Blogs/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/Blogs/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/Blogs/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"mavericreate.top","root":"/Blogs/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/Blogs/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/Blogs/js/utils.js" ></script>
  <script  src="/Blogs/js/color-schema.js" ></script>
  

  

  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/Blogs/">
      <strong>Mavericreate.Gallery</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blogs/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blogs/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blogs/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blogs/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Blogs/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/Blogs/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Ajax内容爬取"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-08-28 00:00" pubdate>
          2025年8月28日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          112 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Ajax内容爬取</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="什么是-Ajax？"><a href="#什么是-Ajax？" class="headerlink" title="什么是 Ajax？"></a>什么是 Ajax？</h1><p>Ajax，全称为 Asynchronous JavaScript and XML，即异步的 JavaScript 和 XML。它不是一门编程语言，而是利用 JavaScript 在保证页面不被刷新、页面链接不改变的情况下与服务器交换数据并更新部分网页的技术。</p>
<p>对于传统的网页，如果想更新其内容，那么必须刷新整个页面，但有了 Ajax，便可以在页面不被全部刷新的情况下更新其内容。在这个过程中，页面实际上是在后台与服务器进行了数据交互，获取到数据之后，再利用 JavaScript 改变网页，这样网页内容就会更新了。</p>
<p>可以到 W3School 上体验几个示例感受一下：<a target="_blank" rel="noopener" href="http://www.w3school.com.cn/ajax/ajax_xmlhttprequest_send.asp">http://www.w3school.com.cn/ajax/ajax_xmlhttprequest_send.asp</a>。</p>
<h2 id="1-实例引入"><a href="#1-实例引入" class="headerlink" title="1. 实例引入"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202251.html#1-%E5%AE%9E%E4%BE%8B%E5%BC%95%E5%85%A5" title="1. 实例引入"></a>1. 实例引入</h2><p>浏览网页的时候，我们会发现很多网页都有下滑查看更多的选项。比如，拿微博来说，以我的主页为例：<a target="_blank" rel="noopener" href="https://m.weibo.cn/u/2830678474">https://m.weibo.cn/u/2830678474</a>，切换到微博页面，一直下滑，可以发现下滑几个微博之后，再向下就没有了，转而会出现一个加载的动画，不一会儿下方就继续出现了新的微博内容，这个过程其实就是 Ajax 加载的过程，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/2jqaq.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>我们注意到页面其实并没有整个刷新，也就意味着页面的链接没有变化，但是网页中却多了新内容，也就是后面刷出来的新微博。这就是通过 Ajax 获取新数据并呈现的过程。</p>
<h2 id="2-基本原理"><a href="#2-基本原理" class="headerlink" title="2. 基本原理"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202251.html#2-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86" title="2. 基本原理"></a>2. 基本原理</h2><p>初步了解了 Ajax 之后，我们再来详细了解它的基本原理。发送 Ajax 请求到网页更新的这个过程可以简单分为以下 3 步：</p>
<ol>
<li>发送请求</li>
<li>解析内容</li>
<li>渲染网页</li>
</ol>
<p>下面我们分别来详细介绍一下这几个过程。</p>
<h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202251.html#%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82" title="发送请求"></a>发送请求</h3><p>我们知道 JavaScript 可以实现页面的各种交互功能，Ajax 也不例外，它也是由 JavaScript 实现的，</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>var xmlhttp;  <br>if (window.XMLHttpRequest) {  <br>  &#x2F;&#x2F;code for IE7+, Firefox, Chrome, Opera, Safari  <br>  xmlhttp &#x3D; new XMLHttpRequest();  <br>} else {  <br>  &#x2F;&#x2F;code for IE6, IE5  <br>  xmlhttp &#x3D; new ActiveXObject(“Microsoft.XMLHTTP”);  <br>}  <br>xmlhttp.onreadystatechange &#x3D; function () {  <br>  if (xmlhttp.readyState &#x3D;&#x3D; 4 &amp;&amp; xmlhttp.status &#x3D;&#x3D; 200) {  <br>    document.getElementById(“myDiv”).innerHTML &#x3D; xmlhttp.responseText;  <br>  }  <br>};  <br>xmlhttp.open(“POST”, “&#x2F;ajax&#x2F;“, true);  <br>xmlhttp.send();</td>
</tr>
</tbody></table>
<p>这是 JavaScript 对 Ajax 最底层的实现，实际上就是新建了 <code>XMLHttpRequest</code> 对象，然后调用 <code>onreadystatechange</code> 属性设置了监听，然后调用 <code>open</code> 和 <code>send</code> 方法向某个链接（也就是服务器）发送了请求。前面用 Python 实现请求发送之后，可以得到响应结果，但这里请求的发送变成 JavaScript 来完成。由于设置了监听，所以当服务器返回响应时，<code>onreadystatechange</code> 对应的方法便会被触发，然后在这个方法里面解析响应内容即可。</p>
<h3 id="解析内容"><a href="#解析内容" class="headerlink" title="解析内容"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202251.html#%E8%A7%A3%E6%9E%90%E5%86%85%E5%AE%B9" title="解析内容"></a>解析内容</h3><p>得到响应之后，<code>onreadystatechange</code> 属性对应的方法便会被触发，此时利用 <code>xmlhttp</code> 的 <code>responseText</code> 属性便可取到响应内容。这类似于 Python 中利用 requests 向服务器发起请求，然后得到响应的过程。那么返回内容可能是 HTML，可能是 JSON，接下来只需要在方法中用 JavaScript 进一步处理即可。比如，如果是 JSON 的话，可以进行解析和转化。</p>
<h3 id="渲染网页"><a href="#渲染网页" class="headerlink" title="渲染网页"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202251.html#%E6%B8%B2%E6%9F%93%E7%BD%91%E9%A1%B5" title="渲染网页"></a>渲染网页</h3><p>JavaScript 有改变网页内容的能力，解析完响应内容之后，就可以调用 JavaScript 来针对解析完的内容对网页进行下一步处理了。比如，通过 <code>document.getElementById().innerHTML</code> 这样的操作，便可以对某个元素内的源代码进行更改，这样网页显示的内容就改变了，这样的操作也被称作 DOM 操作，即对网页文档进行操作，如更改、删除等。</p>
<p>上例中，<code>document.getElementById(&quot;myDiv&quot;).innerHTML=xmlhttp.responseText</code> 便将 ID 为 <code>myDiv</code> 的节点内部的 HTML 代码更改为服务器返回的内容，这样 <code>myDiv</code> 元素内部便会呈现出服务器返回的新数据，网页的部分内容看上去就更新了。</p>
<p>我们观察到，这 3 个步骤其实都是由 JavaScript 完成的，它完成了整个请求、解析和渲染的过程。</p>
<p>再回想微博的下拉刷新，这其实就是 JavaScript 向服务器发送了一个 Ajax 请求，然后获取新的微博数据，将其解析，并将其渲染在网页中。</p>
<p>因此，我们知道，真实的数据其实都是一次次 Ajax 请求得到的，如果想要抓取这些数据，需要知道这些请求到底是怎么发送的，发往哪里，发了哪些参数。如果我们知道了这些，不就可以用 Python 模拟这个发送操作，获取到其中的结果了吗？</p>
<h1 id="Ajax分析方法"><a href="#Ajax分析方法" class="headerlink" title="Ajax分析方法"></a>Ajax分析方法</h1><p>这里还以前面的微博为例，我们知道拖动刷新的内容由 Ajax 加载，而且页面的 URL 没有变化，那么应该到哪里去查看这些 Ajax 请求呢？</p>
<h2 id="1-分析案例"><a href="#1-分析案例" class="headerlink" title="1. 分析案例"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202252.html#1-%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B" title="1. 分析案例"></a>1. 分析案例</h2><p>这里还需要借助浏览器的开发者工具，下面以 Chrome 浏览器为例来介绍。</p>
<p>首先，用 Chrome 浏览器打开微博的链接 <a target="_blank" rel="noopener" href="https://m.weibo.cn/u/2830678474">https://m.weibo.cn/u/2830678474</a>，随后在页面中点击鼠标右键，从弹出的快捷菜单中选择，随后在页面中点击鼠标右键，从弹出的快捷菜单中选择) “检查” 选项，此时便会弹出开发者工具，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/7040b.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>前面也提到过，这里其实就是在页面加载过程中浏览器与服务器之间发送请求和接收响应的所有记录。</p>
<p>Ajax 其实有其特殊的请求类型，它叫作 xhr。在图中我们可以发现一个名称以 getIndex 开头的请求，其 Type 为 xhr，这就是一个 Ajax 请求。用鼠标点击这个请求，可以查看这个请求的详细信息。</p>
<p><img src="https://cdn.cuiqingcai.com/1kiqe.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>在右侧可以观察到其 Request Headers、URL 和 Response Headers 等信息。其中 Request Headers 中有一个信息为 <code>X-Requested-With:XMLHttpRequest</code>，这就标记了此请求是 Ajax 请求，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/t4hm0.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>随后点击一下 Preview，即可看到响应的内容，它是 JSON 格式的。这里 Chrome 为我们自动做了解析，点击箭头即可展开和收起相应内容。</p>
<p>观察可以发现，这里的返回结果是我的个人信息，如昵称、简介、头像等，这也是用来渲染个人主页所使用的数据。JavaScript 接收到这些数据之后，再执行相应的渲染方法，整个页面就渲染出来了。</p>
<p><img src="https://cdn.cuiqingcai.com/kah0s.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>另外，也可以切换到 Response 选项卡，从中观察到真实的返回数据，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/l1z1j.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>接下来，切回到第一个请求，观察一下它的 Response 是什么，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/yfn4s.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>这是最原始的链接 <a target="_blank" rel="noopener" href="https://m.weibo.cn/u/2830678474">https://m.weibo.cn/u/2830678474</a> 返回的结果，其代码只有不到 50 行，结构也非常简单，只是执行了一些 JavaScript。</p>
<p>所以说，我们看到的微博页面的真实数据并不是最原始的页面返回的，而是后来执行 JavaScript 后再次向后台发送了 Ajax 请求，浏览器拿到数据后再进一步渲染出来的。</p>
<h2 id="2-过滤请求"><a href="#2-过滤请求" class="headerlink" title="2. 过滤请求"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202252.html#2-%E8%BF%87%E6%BB%A4%E8%AF%B7%E6%B1%82" title="2. 过滤请求"></a>2. 过滤请求</h2><p>接下来，再利用 Chrome 开发者工具的筛选功能筛选出所有的 Ajax 请求。在请求的上方有一层筛选栏，直接点击 XHR，此时在下方显示的所有请求便都是 Ajax 请求了，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/0xqyh.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>接下来，不断滑动页面，可以看到页面底部有一条条新的微博被刷出，而开发者工具下方也一个个地出现 Ajax 请求，这样我们就可以捕获到所有的 Ajax 请求了。</p>
<p>随意点开一个条目，都可以清楚地看到其 Request URL、Request Headers、Response Headers、Response Body 等内容，此时想要模拟请求和提取就非常简单了。</p>
<p>下图所示的内容便是我的某一页微博的列表信息：</p>
<p><img src="https://cdn.cuiqingcai.com/3gv1x.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>到现在为止，我们已经可以分析出 Ajax 请求的一些详细信息了，接下来只需要用程序模拟这些 Ajax 请求，就可以轻松提取我们所需要的信息了。</p>
<h1 id="Ajax实战"><a href="#Ajax实战" class="headerlink" title="Ajax实战"></a>Ajax实战</h1><p>在上一节中我们已经学习了 Ajax 的基本原理和分析方法，这一节我们来结合一个实际的案例来看一下 Ajax 分析和爬取页面的具体实现。</p>
<h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202253.html#1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C" title="1. 准备工作"></a>1. 准备工作</h2><p>在本节开始之前，我们需要做好如下准备工作：</p>
<ul>
<li>安装好 Python 3（最低为 3.6 版本），并成功运行 Python 3 程序。</li>
<li>了解 Python HTTP 请求库 requests 的基本用法。</li>
<li>了解 Ajax 基础知识和分析 Ajax 的基本方法。</li>
</ul>
<p>以上内容在前面的章节中均有讲解，如尚未准备好，建议先熟悉一下这些内容。</p>
<h2 id="2-爬取目标"><a href="#2-爬取目标" class="headerlink" title="2. 爬取目标"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202253.html#2-%E7%88%AC%E5%8F%96%E7%9B%AE%E6%A0%87" title="2. 爬取目标"></a>2. 爬取目标</h2><p>本节我们以一个示例网站来试验一下 Ajax 的爬取，其链接为：<a target="_blank" rel="noopener" href="https://spa1.scrape.center/%EF%BC%8C%E8%AF%A5%E7%A4%BA%E4%BE%8B%E7%BD%91%E7%AB%99%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82%E6%98%AF%E9%80%9A%E8%BF%87">https://spa1.scrape.center/，该示例网站的数据请求是通过</a> Ajax 完成的，页面的内容是通过 JavaScript 渲染出来的，页面如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/add5o.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705004644681"></p>
<p>可能大家看着这个页面似曾相识，心想这不就是上一个案例的网站吗？但其实不是。这个网站的后台实现逻辑和数据加载方式完全不同。只不过最后呈现的样式是一样的。</p>
<p>这个网站同样支持翻页，可以点击最下方的页码来切换到下一页，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/lyy4e.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705004704636"></p>
<p>点击每一个电影的链接进入详情页，页面结构也是完全一样的，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/y712p.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705004718813"></p>
<p>我们需要爬取的数据也是和原来相同的，包括电影的名称、封面、类别、上映日期、评分、剧情简介等信息。</p>
<p>本节中我们需要完成的目标如下。</p>
<ul>
<li>分析页面数据的加载逻辑。</li>
<li>用 requests 实现 Ajax 数据的爬取。</li>
<li>将每部电影的数据保存成一个 JSON 数据文件。</li>
</ul>
<p>由于本节主要讲解 Ajax，所以对于数据存储和加速部分就不再展开详细实现，主要是讲解 Ajax 的分析和爬取实现。</p>
<p>好，我们现在就开始吧。</p>
<h2 id="3-初步探索"><a href="#3-初步探索" class="headerlink" title="3. 初步探索"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202253.html#3-%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2" title="3. 初步探索"></a>3. 初步探索</h2><p>首先，我们先尝试用之前的 requests 来直接提取页面，看看会得到怎样的结果。用最简单的代码实现一下 requests 获取首页源码的过程，代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>import requests  <br>  <br>url &#x3D; ‘<a target="_blank" rel="noopener" href="https://spa1.scrape.center/">https://spa1.scrape.center/</a>‘  <br>html &#x3D; requests.get(url).text  <br>print(html)</td>
</tr>
</tbody></table>
<p>运行结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=/favicon.ico><title>Scrape | Movie</title><link href=/css/chunk-700f70e1.1126d090.css rel=prefetch><link href=/css/chunk-d1db5eda.0ff76b36.css rel=prefetch><link href=/js/chunk-700f70e1.0548e2b4.js rel=prefetch><link href=/js/chunk-d1db5eda.b564504d.js rel=prefetch><link href=/css/app.ea9d802a.css rel=preload as=style><link href=/js/app.1435ecd5.js rel=preload as=script><link href=/js/chunk-vendors.77daf991.js rel=preload as=script><link href=/css/app.ea9d802a.css rel=stylesheet></head><body><noscript><strong>We’re sorry but portal doesn’t work properly without JavaScript enabled. Please enable it to continue.</strong></noscript><div id=app></div><script src=/js/chunk-vendors.77daf991.js></script><script src=/js/app.1435ecd5.js></script></body></html></td>
</tr>
</tbody></table>
<p>可以看到，爬取结果就只有这么一点 HTML 内容，而我们在浏览器中打开这个页面，却能看到如图所示的结果：</p>
<p><img src="https://cdn.cuiqingcai.com/p2u8d.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705004644681"></p>
<p>在 HTML 中，我们只能看到在源码中引用了一些 JavaScript 和 CSS 文件，并没有观察到有任何电影数据信息。</p>
<p>如果遇到这样的情况，这说明我们现在看到的整个页面便是 JavaScript 渲染得到的，浏览器执行了 HTML 中所引用的 JavaScript 文件，JavaScript 通过调用一些数据加载和页面渲染方法，才最终呈现了图中所示的结果。</p>
<p>在一般情况下，这些数据都是通过 Ajax 来加载的， JavaScript 在后台调用这些 Ajax 数据接口，得到数据之后，再把数据进行解析并渲染呈现出来，得到最终的页面。所以说，要想爬取这个页面，我们可以直接爬取 Ajax 接口获取数据就好了。</p>
<p>在上一节中，我们已经了解了 Ajax 分析的基本方法，下面我们就来分析一下 Ajax 接口的逻辑并实现数据爬取吧。</p>
<h2 id="4-爬取列表页"><a href="#4-爬取列表页" class="headerlink" title="4. 爬取列表页"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202253.html#4-%E7%88%AC%E5%8F%96%E5%88%97%E8%A1%A8%E9%A1%B5" title="4. 爬取列表页"></a>4. 爬取列表页</h2><p>首先我们来分析一下列表页的 Ajax 接口逻辑，打开浏览器开发者工具，切换到 Network 面板，勾选上 Preserve Log 并切换到 XHR 选项卡，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/dpns6.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705004826230"></p>
<p>接着重新刷新页面，再点击第二页、第三页、第四页的按钮，这时候可以观察到页面上的数据发生了变化，同时开发者工具下方就监听到了几个 Ajax 请求，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/x22b1.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705004904893"></p>
<p>由于我们切换了 4 页，每次翻页也出现了对应的 Ajax 请求，我们可以点击查看其请求详情。观察其请求的 URL 和参数以及响应内容是怎样的，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/1ro2i.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705004957327"></p>
<p>这里我们点开了最后个结果，观察到其 Ajax 接口请求的 URL 地址为：<a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/?limit=10&amp;offset=40%EF%BC%8C%E8%BF%99%E9%87%8C%E6%9C%89%E4%B8%A4%E4%B8%AA%E5%8F%82%E6%95%B0%EF%BC%8C%E4%B8%80%E4%B8%AA%E6%98%AF">https://spa1.scrape.center/api/movie/?limit=10&offset=40，这里有两个参数，一个是</a> <code>limit</code>，这里是 10；一个是 <code>offset</code>，这里也是 40。</p>
<p>通过多个 Ajax 接口的参数，我们可以观察到这么一个规律：<code>limit</code> 一直为 10，这就正好对应着每页 10 条数据；<code>offset</code> 在依次变大，页面每加 1 页，<code>offset</code> 就加 10，这就代表着页面的数据偏移量，比如第二页的 <code>offset</code> 为 10 则代表着跳过 10 条数据，返回从 11 条数据开始的结果，再加上 <code>limit</code> 的限制，那就是第 11 条至第 20 条数据的结果。</p>
<p>接着我们再观察一下响应的数据，切换到 Preview 选项卡，结果如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/0ldhk.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705005115792"></p>
<p>可以看到，结果就是一些 JSON 数据，它有一个 <code>results</code> 字段，是一个列表，列表中每一个元素都是一个字典。观察一下字典的内容，这里我们正好可以看到有对应的电影数据的字段了，如 <code>name</code>、<code>alias</code>、<code>cover</code>、<code>categories</code>，对比下浏览器中的真实数据，各个内容完全一致，而且这个数据已经非常结构化了，完全就是我们想要爬取的数据，真的是得来全不费工夫。</p>
<p>这样的话，我们只需要把所有页面的 Ajax 接口构造出来，所有列表页的数据我们都可以轻松获取到了。</p>
<p>我们先定义一些准备工作，导入一些所需的库并定义一些配置，代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>import requests  <br>import logging  <br>  <br>logging.basicConfig(level&#x3D;logging.INFO,  <br>                    format&#x3D;’%(asctime)s - %(levelname)s: %(message)s’)  <br>  <br>INDEX_URL &#x3D; ‘<a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/?limit=%7Blimit%7D&offset=%7Boffset%7D">https://spa1.scrape.center/api/movie/?limit={limit}&amp;offset={offset}</a>‘</td>
</tr>
</tbody></table>
<p>这里我们引入了 requests 和 logging 库，并定义了 logging 的基本配置，接着我们定义了 <code>INDEX_URL</code>，这里把 <code>limit</code> 和 <code>offset</code> 预留出来了变成了占位符，可以动态传入参数构造一个完整的列表页 URL。</p>
<p>下面我们来实现一下详情页的爬取。还是和原来一样，我们先定义一个通用的爬取方法，其代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>def scrape_api(url):  <br>    logging.info(‘scraping %s…’, url)  <br>    try:  <br>        response &#x3D; requests.get(url)  <br>        if response.status_code &#x3D;&#x3D; 200:  <br>            return response.json()  <br>        logging.error(‘get invalid status code %s while scraping %s’, response.status_code, url)  <br>    except requests.RequestException:  <br>        logging.error(‘error occurred while scraping %s’, url, exc_info&#x3D;True)</td>
</tr>
</tbody></table>
<p>这里我们定义了一个 <code>scrape_api</code> 方法，和之前不同的是，这个方法专门用来处理 JSON 接口，最后的 <code>response</code> 调用的是 <code>json</code> 方法，它可以解析响应的内容并将其转化成 JSON 字符串。</p>
<p>接着在这个基础之上，我们定义一个爬取列表页的方法，其代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>LIMIT &#x3D; 10  <br>  <br>def scrape_index(page):  <br>    url &#x3D; INDEX_URL.format(limit&#x3D;LIMIT, offset&#x3D;LIMIT * (page - 1))  <br>    return scrape_api(url)</td>
</tr>
</tbody></table>
<p>这里我们定义了一个 <code>scrape_index</code> 方法，它接收一个参数 <code>page</code>，该参数代表列表页的页码。</p>
<p>这里我们先构造了一个 <code>url</code>，通过字符串的 <code>format</code> 方法，传入 <code>limit</code> 和 <code>offset</code> 的值。这里 <code>limit</code> 就直接使用了全局变量 <code>LIMIT</code> 的值；<code>offset</code> 则是动态计算的，就是页码数减一再乘以 <code>limit</code>，比如第一页 <code>offset</code> 就是 0，第二页 <code>offset</code> 就是 10，以此类推。构造好了 <code>url</code> 之后，直接调用 <code>scrape_api</code> 方法并返回结果即可。</p>
<p>这样我们就完成了列表页的爬取，每次请求都会得到一页 10 部的电影数据。</p>
<p>由于这时爬取到的数据已经是 JSON 类型了，所以我们不用像之前那样去解析 HTML 代码来提取数据了，爬到的数据就是我们想要的结构化数据，因此解析这一步就可以直接省略啦。</p>
<p>到此为止，我们能成功爬取列表页并提取出电影列表信息了。</p>
<h2 id="5-爬取详情页"><a href="#5-爬取详情页" class="headerlink" title="5. 爬取详情页"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202253.html#5-%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5" title="5. 爬取详情页"></a>5. 爬取详情页</h2><p>这时候我们已经可以拿到每一页的电影数据了，但是看看这些数据实际上还缺少了一些我们想要的信息，如剧情简介等信息，所以需要进一步进入到详情页来获取这些内容。</p>
<p>这时候点击任意一部电影，如《教父》，进入其详情页，这时可以发现页面的 URL 已经变成了 <a target="_blank" rel="noopener" href="https://spa1.scrape.center/detail/40">https://spa1.scrape.center/detail/40</a>，页面也成功展示了详情页的信息，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/tuum6.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705005243372"></p>
<p>另外，我们也可以观察到在开发者工具中又出现了一个 Ajax 请求，其 URL 为 <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/40/">https://spa1.scrape.center/api/movie/40/</a>，通过 Preview 选项卡也能看到 Ajax 请求对应响应的信息，如图 所示。</p>
<p><img src="https://cdn.cuiqingcai.com/y1o4n.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20200601141202684"><br>稍加观察就可以发现，Ajax 请求的 URL 后面有一个参数是可变的，这个参数就是电影的 <code>id</code>，这里是 40，对应《教父》这部电影。</p>
<p>如果我们想要获取 <code>id</code> 为 50 的电影，只需要把 URL 最后的参数改成 50 即可，即 <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/50/">https://spa1.scrape.center/api/movie/50/</a>，请求这个新的 URL 我们就能获取 <code>id</code> 为 50 的电影所对应的数据了。</p>
<p>同样，响应结果也是结构化的 JSON 数据，字段也非常规整，我们直接爬取即可。</p>
<p>现在分析好了详情页的数据提取逻辑，那么怎么和列表页关联起来呢？这个 <code>id</code> 哪里来呢？我们回过头来再看看列表页的接口返回数据，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/bzc8x.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>可以看到，列表页原本的返回数据就带了 <code>id</code> 这个字段，所以我们只需要拿列表页结果中的 <code>id</code> 来构造详情页的 Ajax 请求的 URL 就好了。</p>
<p>接着，我们就先定义一个详情页的爬取逻辑，代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>DETAIL_URL &#x3D; ‘<a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/%7Bid%7D">https://spa1.scrape.center/api/movie/{id}</a>‘  <br>  <br>def scrape_detail(id):  <br>    url &#x3D; DETAIL_URL.format(id&#x3D;id)  <br>    return scrape_api(url)</td>
</tr>
</tbody></table>
<p>这里我们定义了一个 <code>scrape_detail</code> 方法，它接收一个参数 <code>id</code>。这里的实现也非常简单，先根据定义好的 <code>DETAIL_URL</code> 加 <code>id</code> 构造一个真实的详情页 Ajax 请求的 URL，然后直接调用 <code>scrape_api</code> 方法传入这个 <code>url</code> 即可。</p>
<p>接着，我们定义一个总的调用方法，将以上方法串联调用起来，代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>TOTAL_PAGE &#x3D; 10  <br>  <br>def main():  <br>    for page in range(1, TOTAL_PAGE + 1):  <br>        index_data &#x3D; scrape_index(page)  <br>        for item in index_data.get(‘results’):  <br>            id &#x3D; item.get(‘id’)  <br>            detail_data &#x3D; scrape_detail(id)  <br>            logging.info(‘detail data %s’, detail_data)  <br>  <br>if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘:  <br>    main()</td>
</tr>
</tbody></table>
<p>这里我们定义了一个 <code>main</code> 方法，首先遍历获取了页码 <code>page</code>，然后把 <code>page</code> 当参数传递给了 <code>scrape_index</code> 方法，得到列表页的数据。接着我们遍历每个列表页的每个结果，获取到每部电影的 <code>id</code>，然后把 <code>id</code> 当作参数传递给 <code>scrape_detail</code> 方法来爬取每部电影的详情数据，并将其赋值为 <code>detail_data</code>，输出即可。</p>
<p>运行结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>2020-03-19 02:51:55,981 - INFO: scraping <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/?limit=10&offset=0">https://spa1.scrape.center/api/movie/?limit=10&amp;offset=0</a>…  <br>2020-03-19 02:51:56,446 - INFO: scraping <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/1">https://spa1.scrape.center/api/movie/1</a>…  <br>2020-03-19 02:51:56,638 - INFO: detail data {‘id’: 1, ‘name’: ‘霸王别姬’, ‘alias’: ‘Farewell My Concubine’, ‘cover’: ‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/ce4da3e03e655b5b88ed31b5cd7896cf62472.jpg@464w_644h_1e_1c">https://p0.meituan.net/movie/ce4da3e03e655b5b88ed31b5cd7896cf62472.jpg@464w_644h_1e_1c</a>‘, ‘categories’: [‘剧情’, ‘爱情’], ‘regions’: [‘中国大陆’, ‘中国香港’], ‘actors’: [{‘name’: ‘张国荣’, ‘role’: ‘程蝶衣’, …}, …], ‘directors’: [{‘name’: ‘陈凯歌’, ‘image’: ‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/8f9372252050095067e0e8d58ef3d939156407.jpg@128w_170h_1e_1c'%7D]">https://p0.meituan.net/movie/8f9372252050095067e0e8d58ef3d939156407.jpg@128w_170h_1e_1c&#39;}]</a>, ‘score’: 9.5, ‘rank’: 1, ‘minute’: 171, ‘drama’: ‘影片借一出《霸王别姬》的京戏，牵扯出三个人之间一段随时代风云变幻的爱恨情仇。段小楼（张丰毅 饰）与程蝶衣（张国荣 饰）是一对打小一起长大的师兄弟，…’, ‘photos’: […], ‘published_at’: ‘1993-07-26’, ‘updated_at’: ‘2020-03-07T16:31:36.967843Z’}  <br>2020-03-19 02:51:56,640 - INFO: scraping <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/2">https://spa1.scrape.center/api/movie/2</a>…  <br>2020-03-19 02:51:56,813 - INFO: detail data {‘id’: 2, ‘name’: ‘这个杀手不太冷’, ‘alias’: ‘Léon’, ‘cover’: ‘<a target="_blank" rel="noopener" href="https://p1.meituan.net/movie/6bea9af4524dfbd0b668eaa7e187c3df767253.jpg@464w_644h_1e_1c">https://p1.meituan.net/movie/6bea9af4524dfbd0b668eaa7e187c3df767253.jpg@464w_644h_1e_1c</a>‘, ‘categories’: [‘剧情’, ‘动作’, ‘犯罪’], ‘regions’: [‘法国’], ‘actors’: [{‘name’: ‘让·雷诺’, ‘role’: ‘莱昂 Leon’, …}, …], ‘directors’: [{‘name’: ‘吕克·贝松’, ‘image’: ‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/0e7d67e343bd3372a714093e8340028d40496.jpg@128w_170h_1e_1c'%7D]">https://p0.meituan.net/movie/0e7d67e343bd3372a714093e8340028d40496.jpg@128w_170h_1e_1c&#39;}]</a>, ‘score’: 9.5, ‘rank’: 3, ‘minute’: 110, ‘drama’: ‘里昂（让·雷诺 饰）是名孤独的职业杀手，受人雇佣。一天，邻居家小姑娘马蒂尔德（纳塔丽·波特曼 饰）敲开他的房门，要求在他那里暂避杀身之祸。…’, ‘photos’: […], ‘published_at’: ‘1994-09-14’, ‘updated_at’: ‘2020-03-07T16:31:43.826235Z’}  <br>…</td>
</tr>
</tbody></table>
<p>由于内容较多，这里省略了部分内容。</p>
<p>可以看到，其实整个爬取工作就已经完成了，这里会顺次爬取每一页列表页 Ajax 接口，然后去顺次爬取每部电影的详情页 Ajax 接口，打印出每部电影的 Ajax 接口响应数据，而且都是 JSON 格式。这样，所有电影的详情数据都会被我们爬取到啦。</p>
<h2 id="6-保存数据"><a href="#6-保存数据" class="headerlink" title="6. 保存数据"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202253.html#6-%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE" title="6. 保存数据"></a>6. 保存数据</h2><p>好，成功提取到详情页信息之后，我们下一步就要把数据保存起来了。在前面我们学习了 MongoDB 的相关操作，接下来我们就把数据保存到 MongoDB 吧。</p>
<p>在这之前，请确保现在有一个可以正常连接和使用的 MongoDB 数据库，这里我就以本地 localhost 的 M 哦能够 DB 数据库为例来进行操作，其运行在 27017 端口上，无用户名和密码。</p>
<p>将数据导入 MongoDB 需要用到 PyMongo 这个库。接下来我们把它们引入一下，然后同时定义一下 MongoDB 的连接配置，实现如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>MONGO_CONNECTION_STRING &#x3D; ‘mongodb:&#x2F;&#x2F;localhost:27017’  <br>MONGO_DB_NAME &#x3D; ‘movies’  <br>MONGO_COLLECTION_NAME &#x3D; ‘movies’  <br>  <br>import pymongo  <br>client &#x3D; pymongo.MongoClient(MONGO_CONNECTION_STRING)  <br>db &#x3D; client[‘movies’]  <br>collection &#x3D; db[‘movies’]</td>
</tr>
</tbody></table>
<p>在这里我们声明了几个变量，介绍如下：</p>
<ul>
<li>MONGO_CONNECTION_STRING：MongoDB 的连接字符串，里面定义了 MongoDB 的基本连接信息，如 host、port，还可以定义用户名密码等内容。</li>
<li>MONGO_DB_NAME：MongoDB 数据库的名称。</li>
<li>MONGO_COLLECTION_NAME：MongoDB 的集合名称。</li>
</ul>
<p>这里我们用 MongoClient 声明了一个连接对象，然后依次声明了存储的数据库和集合。</p>
<p>接下来，我们再实现一个将数据保存到 MongoDB 的方法，实现如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>def save_data(data):  <br>    collection.update_one({  <br>        ‘name’: data.get(‘name’)  <br>    }, {  <br>        ‘$set’: data  <br>    }, upsert&#x3D;True)</td>
</tr>
</tbody></table>
<p>在这里我们声明了一个 save_data 方法，它接收一个 data 参数，也就是我们刚才提取的电影详情信息。在方法里面，我们调用了 update_one 方法，第一个参数是查询条件，即根据 name 进行查询；第二个参数就是 data 对象本身，就是所有的数据，这里我们用 <code>$set</code> 操作符表示更新操作；第三个参数很关键，这里实际上是 upsert 参数，如果把这个设置为 True，则可以做到存在即更新，不存在即插入的功能，更新会根据第一个参数设置的 name 字段，所以这样可以防止数据库中出现同名的电影数据。</p>
<blockquote>
<p>注：实际上电影可能有同名，但该场景下的爬取数据没有同名情况，当然这里更重要的是实现 MongoDB 的去重操作。</p>
</blockquote>
<p>好的，那么接下来 main 方法稍微改写一下就好了，改写如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>def main():  <br>    for page in range(1, TOTAL_PAGE + 1):  <br>        index_data &#x3D; scrape_index(page)  <br>        for item in index_data.get(‘results’):  <br>            id &#x3D; item.get(‘id’)  <br>            detail_data &#x3D; scrape_detail(id)  <br>            logging.info(‘detail data %s’, detail_data)  <br>            save_data(detail_data)  <br>            logging.info(‘data saved successfully’)</td>
</tr>
</tbody></table>
<p>这里就是加了 save_data 方法的调用，并加了一些日志信息。</p>
<p>重新运行，我们看下输出结果：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>2020-03-19 02:51:06,323 - INFO: scraping <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/?limit=10&offset=0">https://spa1.scrape.center/api/movie/?limit=10&amp;offset=0</a>…  <br>2020-03-19 02:51:06,440 - INFO: scraping <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/1">https://spa1.scrape.center/api/movie/1</a>…  <br>2020-03-19 02:51:06,551 - INFO: detail data {‘id’: 1, ‘name’: ‘霸王别姬’, ‘alias’: ‘Farewell My Concubine’, ‘cover’: ‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/ce4da3e03e655b5b88ed31b5cd7896cf62472.jpg@464w_644h_1e_1c">https://p0.meituan.net/movie/ce4da3e03e655b5b88ed31b5cd7896cf62472.jpg@464w_644h_1e_1c</a>‘, ‘categories’: [‘剧情’, ‘爱情’], ‘regions’: [‘中国大陆’, ‘中国香港’], ‘actors’: [{‘name’: ‘张国荣’, ‘role’: ‘程蝶衣’, ‘image’: ‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/5de69a492dcbd3f4b014503d4e95d46c28837.jpg@128w_170h_1e_1c'%7D">https://p0.meituan.net/movie/5de69a492dcbd3f4b014503d4e95d46c28837.jpg@128w_170h_1e_1c&#39;}</a>, …, {‘name’: ‘方征’, ‘role’: ‘嫖客’, ‘image’: ‘<a target="_blank" rel="noopener" href="https://p1.meituan.net/movie/39687137b23bc9727b47fd24bdcc579b97618.jpg@128w_170h_1e_1c'%7D]">https://p1.meituan.net/movie/39687137b23bc9727b47fd24bdcc579b97618.jpg@128w_170h_1e_1c&#39;}]</a>, ‘directors’: [{‘name’: ‘陈凯歌’, ‘image’: ‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/8f9372252050095067e0e8d58ef3d939156407.jpg@128w_170h_1e_1c'%7D]">https://p0.meituan.net/movie/8f9372252050095067e0e8d58ef3d939156407.jpg@128w_170h_1e_1c&#39;}]</a>, ‘score’: 9.5, ‘rank’: 1, ‘minute’: 171, ‘drama’: ‘影片借一出《霸王别姬》的京戏，牵扯出三个人之间一段随时代风云变幻的爱恨情仇。段小楼（张丰毅 饰）与程蝶衣（张国荣 饰）是一对打小一起长大的师兄弟，两人一个演生，一个饰旦，一向配合天衣无缝，尤其一出《霸王别姬》，更是誉满京城，为此，两人约定合演一辈子《霸王别姬》。但两人对戏剧与人生关系的理解有本质不同，段小楼深知戏非人生，程蝶衣则是人戏不分。段小楼在认为该成家立业之时迎娶了名妓菊仙（巩俐 饰），致使程蝶衣认定菊仙是可耻的第三者，使段小楼做了叛徒，自此，三人围绕一出《霸王别姬》生出的爱恨情仇战开始随着时代风云的变迁不断升级，终酿成悲剧。’, ‘photos’: [‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/45be438368bb291e501dc523092f0ac8193424.jpg@106w_106h_1e_1c">https://p0.meituan.net/movie/45be438368bb291e501dc523092f0ac8193424.jpg@106w_106h_1e_1c</a>‘, …, ‘<a target="_blank" rel="noopener" href="https://p0.meituan.net/movie/0d952107429db3029b64bf4f25bd762661696.jpg@106w_106h_1e_1c']">https://p0.meituan.net/movie/0d952107429db3029b64bf4f25bd762661696.jpg@106w_106h_1e_1c&#39;]</a>, ‘published_at’: ‘1993-07-26’, ‘updated_at’: ‘2020-03-07T16:31:36.967843Z’}  <br>2020-03-19 02:51:06,583 - INFO: data saved successfully  <br>2020-03-19 02:51:06,583 - INFO: scraping <a target="_blank" rel="noopener" href="https://spa1.scrape.center/api/movie/2">https://spa1.scrape.center/api/movie/2</a>…</td>
</tr>
</tbody></table>
<p>由于输出内容较多，这里省略了部分内容。</p>
<p>我们可以看到这里我们成功爬取到了数据，并且提示了数据存储成功的信息，没有任何报错信息。</p>
<p>接下来我们使用 Robo 3T 连接 MongoDB 数据库看下爬取的结果，由于我使用的是本地的 MongoDB，所以在 Robo 3T 里面我直接输入 localhost 的连接信息即可，这里请替换成自己的 MongoDB 连接信息，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/imum3.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>连接之后我们便可以在 movies 这个数据库，movies 这个集合下看到我们刚才爬取的数据了，如图所示：</p>
<p><img src="https://cdn.cuiqingcai.com/ammal.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>可以看到数据就是以 JSON 格式存储的，一条数据就对应一部电影的信息，各种嵌套信息也一目了然，同时第三列还有数据类型标识。</p>
<p>这样就证明我们的数据就成功存储到 MongoDB 里了。</p>
<h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202253.html#7-%E6%80%BB%E7%BB%93" title="7. 总结"></a>7. 总结</h2><p>本节中我们通过一个案例来体会了 Ajax 分析和爬取的基本流程，希望大家通过本节能够更加熟悉 Ajax 的分析和爬取实现。</p>
<p>另外，我们也观察到，由于 Ajax 接口大部分返回的是 JSON 数据，所以在一定程度上可以避免一些数据提取的工作，这也在一定程度上减轻了工作量。</p>
<p>本节代码：<a target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/ScrapeSpa1%E3%80%82">https://github.com/Python3WebSpider/ScrapeSpa1。</a></p>
<h1 id="经典动态渲染工具-Selenium-的使用"><a href="#经典动态渲染工具-Selenium-的使用" class="headerlink" title="# 经典动态渲染工具 Selenium 的使用"></a># 经典动态渲染工具 Selenium 的使用</h1><p>前面我们讲解了 Ajax 的分析方法，利用 Ajax 接口我们可以非常方便地完成数据爬取。只要我们能找到 Ajax 接口的规律，就可以通过某些参数构造出对应的请求，数据自然就能轻松爬取到。</p>
<p>但是在很多情况下，一些 Ajax 请求的接口通常会包含加密参数，如 <code>token</code>、<code>sign</code> 等，如：<a target="_blank" rel="noopener" href="https://spa2.scrape.center/%EF%BC%8C%E5%AE%83%E7%9A%84">https://spa2.scrape.center/，它的</a> Ajax 接口是包含一个 <code>token</code> 参数的，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/y6w4q.png" srcset="/Blogs/img/loading.gif" lazyload alt="包含 `token` 参数的 Ajax 接口"></p>
<p>由于请求接口时必须加上 <code>token</code> 参数，所以我们如果不深入分析找到 <code>token</code> 的构造逻辑，是难以直接模拟这些 Ajax 请求的。</p>
<p>此时解决方法通常有两种：一种就是深挖其中的逻辑，把其中 <code>token</code> 的构造逻辑完全找出来，再用 Python 复现，构造 Ajax 请求；另外一种方法就是直接通过模拟浏览器的方式来绕过这个过程，因为在浏览器里我们可以看到这个数据，如果能把看到的数据直接爬取下来，当然也就能获取对应的信息了。</p>
<p>由于第一种方法难度较高，这里我们就先介绍第二种方法：模拟浏览器爬取。</p>
<p>这里使用的工具为 Selenium，这里就来先了解一下 Selenium 的基本使用方法。</p>
<p>Selenium 是一个自动化测试工具，利用它可以驱动浏览器执行特定的动作，如点击、下拉等操作，同时还可以获取浏览器当前呈现的页面的源代码，做到可见即可爬。对于一些 JavaScript 动态渲染的页面来说，此种抓取方式非常有效。本节中，就让我们来感受一下它的强大之处吧。</p>
<h2 id="1-准备工作-1"><a href="#1-准备工作-1" class="headerlink" title="1. 准备工作"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C" title="1. 准备工作"></a>1. 准备工作</h2><p>本节以 Chrome 为例来讲解 Selenium 的用法。在开始之前，请确保已经正确安装好了 Chrome 浏览器并配置好了 ChromeDriver。另外，还需要正确安装好 Python 的 Selenium 库。</p>
<p>安装方法可以参考：<a target="_blank" rel="noopener" href="https://setup.scrape.center/selenium%EF%BC%8C%E5%85%A8%E9%83%A8%E9%85%8D%E7%BD%AE%E5%AE%8C%E6%88%90%E4%B9%8B%E5%90%8E%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BE%BF%E5%8F%AF%E4%BB%A5%E5%BC%80%E5%A7%8B%E6%9C%AC%E8%8A%82%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%BA%86%E3%80%82">https://setup.scrape.center/selenium，全部配置完成之后，我们便可以开始本节的学习了。</a></p>
<h2 id="2-基本用法"><a href="#2-基本用法" class="headerlink" title="2. 基本用法"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#2-%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95" title="2. 基本用法"></a>2. 基本用法</h2><p>准备工作做好之后，首先来大体看一下 Selenium 的功能。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>from selenium.webdriver.common.by import By  <br>from selenium.webdriver.common.keys import Keys  <br>from selenium.webdriver.support import expected_conditions as EC  <br>from selenium.webdriver.support.wait import WebDriverWait  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>try:  <br>    browser.get(‘<a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com</a>‘)  <br>    input &#x3D; browser.find_element_by_id(‘kw’)  <br>    input.send_keys(‘Python’)  <br>    input.send_keys(Keys.ENTER)  <br>    wait &#x3D; WebDriverWait(browser, 10)  <br>    wait.until(EC.presence_of_element_located((By.ID, ‘content_left’)))  <br>    print(browser.current_url)  <br>    print(browser.get_cookies())  <br>    print(browser.page_source)  <br>finally:  <br>    browser.close()</td>
</tr>
</tbody></table>
<p>运行代码后发现，会自动弹出一个 Chrome 浏览器。浏览器首先会跳转到百度，然后在搜索框中输入 Python，接着跳转到搜索结果页，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/fu94j.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>此时在控制台的输出结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td><a target="_blank" rel="noopener" href="https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=0&rsv_idx=1&tn=baidu&wd=Python&rsv_pq=c94d0df9000a72d0&rsv_t=07099xvun1ZmC0bf6eQvygJ43IUTTUOl5FCJVPgwG2YREs70GplJjH2F+CQ&rqlang=cn&rsv_enter=1&rsv_sug3=6&rsv_sug2=0&inputT=87&rsv_sug4=87">https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=1&amp;tn=baidu&amp;wd=Python&amp;rsv_pq=c94d0df9000a72d0&amp;rsv_t=07099xvun1ZmC0bf6eQvygJ43IUTTUOl5FCJVPgwG2YREs70GplJjH2F%2BCQ&amp;rqlang=cn&amp;rsv_enter=1&amp;rsv_sug3=6&amp;rsv_sug2=0&amp;inputT=87&amp;rsv_sug4=87</a>  <br>[{‘secure’: False, ‘value’: ‘B490B5EBF6F3CD402E515D22BCDA1598’, ‘domain’: ‘.baidu.com’, ‘path’: ‘&#x2F;‘, ‘httpOnly’: False, ‘name’: ‘BDORZ’, ‘expiry’: 1491688071.707553}, {‘secure’: False, ‘value’: ‘22473_1441_21084_17001’, ‘domain’: ‘.baidu.com’, ‘path’: ‘&#x2F;‘, ‘httpOnly’: False, ‘name’: ‘H_PS_PSSID’}, {‘secure’: False, ‘value’: ‘12883875381399993259_00_0_I_R_2_0303_C02F_N_I_I_0’, ‘domain’: ‘.<a target="_blank" rel="noopener" href="http://www.baidu.com/">www.baidu.com</a>‘, ‘path’: ‘&#x2F;‘, ‘httpOnly’: False, ‘name’: ‘__bsi’, ‘expiry’: 1491601676.69722}]  <br><!DOCTYPE html><!--STATUS OK-->…</html></td>
</tr>
</tbody></table>
<p>源代码过长，在此省略。可以看到，我们得到的当前 URL、Cookies 和源代码都是浏览器中的真实内容。</p>
<p>所以说，如果用 Selenium 来驱动浏览器加载网页的话，就可以直接拿到 JavaScript 渲染的结果了，不用担心使用的是什么加密系统。</p>
<p>下面来详细了解一下 Selenium 的用法。</p>
<h2 id="3-声明浏览器对象"><a href="#3-声明浏览器对象" class="headerlink" title="3. 声明浏览器对象"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#3-%E5%A3%B0%E6%98%8E%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AF%B9%E8%B1%A1" title="3. 声明浏览器对象"></a>3. 声明浏览器对象</h2><p>Selenium 支持非常多的浏览器，如 Chrome、Firefox、Edge 等，还有 Android、BlackBerry 等手机端的浏览器。我们可以用如下方式初始化：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser &#x3D; webdriver.Firefox()  <br>browser &#x3D; webdriver.Edge()  <br>browser &#x3D; webdriver.Safari()</td>
</tr>
</tbody></table>
<p>这样就完成了浏览器对象的初始化并将其赋值为 <code>browser</code> 对象。接下来，我们要做的就是调用 <code>browser</code> 对象，让其执行各个动作以模拟浏览器操作。</p>
<h2 id="4-访问页面"><a href="#4-访问页面" class="headerlink" title="4. 访问页面"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#4-%E8%AE%BF%E9%97%AE%E9%A1%B5%E9%9D%A2" title="4. 访问页面"></a>4. 访问页面</h2><p>我们可以用 <code>get</code> 方法来请求网页，其参数传入链接 URL 即可。比如，这里用 <code>get</code> 方法访问淘宝，然后打印出源代码，代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com</a>‘)  <br>print(browser.page_source)  <br>browser.close()</td>
</tr>
</tbody></table>
<p>运行后发现，此时弹出了 Chrome 浏览器并且自动访问了淘宝，然后控制台输出了淘宝页面的源代码，随后浏览器关闭。</p>
<p>通过这几行简单的代码，我们可以实现浏览器的驱动并获取网页源码，非常便捷。</p>
<h2 id="5-查找节点"><a href="#5-查找节点" class="headerlink" title="5. 查找节点"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#5-%E6%9F%A5%E6%89%BE%E8%8A%82%E7%82%B9" title="5. 查找节点"></a>5. 查找节点</h2><p>Selenium 可以驱动浏览器完成各种操作，比如填充表单、模拟点击等。比如，我们想要完成向某个输入框输入文字的操作，总需要知道这个输入框在哪里吧？而 Selenium 提供了一系列查找节点的方法，我们可以用这些方法来获取想要的节点，以便下一步执行一些动作或者提取信息。</p>
<h3 id="单个节点"><a href="#单个节点" class="headerlink" title="单个节点"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#%E5%8D%95%E4%B8%AA%E8%8A%82%E7%82%B9" title="单个节点"></a>单个节点</h3><p>比如，想要从淘宝页面中提取搜索框这个节点，首先要观察它的源代码，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/lwmpo.png" srcset="/Blogs/img/loading.gif" lazyload alt="源代码"></p>
<p>可以发现，它的 <code>id</code> 是 <code>q</code>，<code>name</code> 也是 <code>q</code>。此外，还有许多其他属性，此时我们就可以用多种方式获取它了。比如，<code>find_element_by_name</code> 是根据 <code>name</code> 值获取，<code>find_element_by_id</code> 是根据 <code>id</code> 获取。另外，还有根据 XPath、CSS 选择器等获取的方式。</p>
<p>下面我们用代码实现一下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com</a>‘)  <br>input_first &#x3D; browser.find_element_by_id(‘q’)  <br>input_second &#x3D; browser.find_element_by_css_selector(‘#q’)  <br>input_third &#x3D; browser.find_element_by_xpath(‘&#x2F;&#x2F;*[@id&#x3D;”q”]’)  <br>print(input_first, input_second, input_third)  <br>browser.close()</td>
</tr>
</tbody></table>
<p>这里我们使用 3 种方式获取输入框，分别是根据 ID、CSS 选择器和 XPath 获取，它们返回的结果完全一致。运行结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”5e53d9e1c8646e44c14c1c2880d424af”, element&#x3D;”0.5649563096161541-1”)&gt;  <br>&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”5e53d9e1c8646e44c14c1c2880d424af”, element&#x3D;”0.5649563096161541-1”)&gt;  <br>&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”5e53d9e1c8646e44c14c1c2880d424af”, element&#x3D;”0.5649563096161541-1”)&gt;</td>
</tr>
</tbody></table>
<p>可以看到，这 3 个节点都是 <code>WebElement</code> 类型，是完全一致的。</p>
<p>下面列出所有获取单个节点的方法：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>find_element__id  <br>find_element__name  <br>find_element__xpath  <br>find_element__link_text  <br>find_element__partial_link_text  <br>find_element__tag_name  <br>find_element__class_name  <br>find_element__css_selector</td>
</tr>
</tbody></table>
<p>另外，Selenium 还提供了通用方法 <code>find_element</code>，它需要传入两个参数：查找方式 <code>By</code> 和值。实际上，它就是 <code>find_element_by_id</code> 这种方法的通用函数版本，比如 <code>find_element_by_id(id)</code> 就等价于 <code>find_element(By.ID, id)</code>，二者得到的结果完全一致。我们用代码实现一下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>from selenium.webdriver.common.by import By  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com</a>‘)  <br>input_first &#x3D; browser.find_element(By.ID, ‘q’)  <br>print(input_first)  <br>browser.close()</td>
</tr>
</tbody></table>
<p>实际上，这种查找方式的功能和上面列举的查找函数完全一致，不过参数更加灵活。</p>
<h3 id="多个节点"><a href="#多个节点" class="headerlink" title="多个节点"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#%E5%A4%9A%E4%B8%AA%E8%8A%82%E7%82%B9" title="多个节点"></a>多个节点</h3><p>如果查找的目标在网页中只有一个，那么完全可以用 <code>find_element</code> 方法。但如果有多个节点，再用 <code>find_element</code> 方法查找，就只能得到第一个节点了。如果要查找所有满足条件的节点，需要用 <code>find_elements</code> 这样的方法。注意，在这个方法的名称中，element 多了一个 s，注意区分。</p>
<p>比如，要查找淘宝左侧导航条的所有条目，就可以这样来实现：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com</a>‘)  <br>lis &#x3D; browser.find_elements_by_css_selector(‘.service-bd li’)  <br>print(lis)  <br>browser.close()</td>
</tr>
</tbody></table>
<p>运行结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>[&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”c26290835d4457ebf7d96bfab3740d19”, element&#x3D;”0.09221044033125603-1”)&gt;, &lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”c26290835d4457ebf7d96bfab3740d19”, element&#x3D;”0.09221044033125603-2”)&gt;, &lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”c26290835d4457ebf7d96bfab3740d19”, element&#x3D;”0.09221044033125603-3”)&gt;…&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”c26290835d4457ebf7d96bfab3740d19”, element&#x3D;”0.09221044033125603-16”)&gt;]</td>
</tr>
</tbody></table>
<p>这里简化了输出结果，中间部分省略。</p>
<p>可以看到，得到的内容变成了列表类型，列表中的每个节点都是 <code>WebElement</code> 类型。</p>
<p>也就是说，如果我们用 <code>find_element</code> 方法，只能获取匹配的第一个节点，结果是 <code>WebElement</code> 类型。如果用 <code>find_elements</code> 方法，则结果是列表类型，列表中的每个节点都是 <code>WebElement</code> 类型。</p>
<p>这里列出所有获取多个节点的方法：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>find_elements_by_id  <br>find_elements_by_name  <br>find_elements_by_xpath  <br>find_elements_by_link_text  <br>find_elements_by_partial_link_text  <br>find_elements_by_tag_name  <br>find_elements_by_class_name  <br>find_elements_by_css_selector</td>
</tr>
</tbody></table>
<p>当然，我们也可以直接用 <code>find_elements</code> 方法来选择，这时可以这样写：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>lis &#x3D; browser.find_elements(By.CSS_SELECTOR, ‘.service-bd li’)</td>
</tr>
</tbody></table>
<p>结果是完全一致的。</p>
<h2 id="6-节点交互"><a href="#6-节点交互" class="headerlink" title="6. 节点交互"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#6-%E8%8A%82%E7%82%B9%E4%BA%A4%E4%BA%92" title="6. 节点交互"></a>6. 节点交互</h2><p>Selenium 可以驱动浏览器来执行一些操作，也就是说可以让浏览器模拟执行一些动作。比较常见的用法有：输入文字时用 <code>send_keys</code> 方法，清空文字时用 <code>clear</code> 方法，点击按钮时用 <code>click</code> 方法。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>import time  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com</a>‘)  <br>input &#x3D; browser.find_element_by_id(‘q’)  <br>input.send_keys(‘iPhone’)  <br>time.sleep(1)  <br>input.clear()  <br>input.send_keys(‘iPad’)  <br>button &#x3D; browser.find_element_by_class_name(‘btn-search’)  <br>button.click()</td>
</tr>
</tbody></table>
<p>这里首先驱动浏览器打开淘宝，然后用 <code>find_element_by_id</code> 方法获取输入框，然后用 <code>send_keys</code> 方法输入 iPhone 文字，等待一秒后用 <code>clear</code> 方法清空输入框，再次调用 <code>send_keys</code> 方法输入 iPad 文字，之后再用 <code>find_element_by_class_name</code> 方法获取搜索按钮，最后调用 <code>click</code> 方法完成搜索动作。</p>
<p>通过上面的方法，我们完成了一些常见节点的操作，更多的操作可以参见官方文档的交互动作介绍 ：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement%E3%80%82">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement。</a></p>
<h2 id="7-动作链"><a href="#7-动作链" class="headerlink" title="7. 动作链"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#7-%E5%8A%A8%E4%BD%9C%E9%93%BE" title="7. 动作链"></a>7. 动作链</h2><p>在上面的实例中，一些交互动作都是针对某个节点执行的。比如，对于输入框，我们就调用它的输入文字和清空文字方法；对于按钮，就调用它的点击方法。其实，还有另外一些操作，它们没有特定的执行对象，比如鼠标拖曳、键盘按键等，这些动作用另一种方式来执行，那就是动作链。</p>
<p>比如，现在实现一个节点的拖曳操作，将某个节点从一处拖曳到另外一处，可以这样实现：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>from selenium.webdriver import ActionChains  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>url &#x3D; ‘<a target="_blank" rel="noopener" href="http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable">http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable</a>‘  <br>browser.get(url)  <br>browser.switch_to.frame(‘iframeResult’)  <br>source &#x3D; browser.find_element_by_css_selector(‘#draggable’)  <br>target &#x3D; browser.find_element_by_css_selector(‘#droppable’)  <br>actions &#x3D; ActionChains(browser)  <br>actions.drag_and_drop(source, target)  <br>actions.perform()</td>
</tr>
</tbody></table>
<p>首先，打开网页中的一个拖曳实例，然后依次选中要拖曳的节点和拖曳到的目标节点，接着声明 <code>ActionChains</code> 对象并将其赋值为 <code>actions</code> 变量，然后通过调用 <code>actions</code> 变量的 <code>drag_and_drop</code> 方法，再调用 <code>perform</code> 方法执行动作，此时就完成了拖曳操作，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/7650u.jpg" srcset="/Blogs/img/loading.gif" lazyload alt="拖曳前页面"></p>
<p><img src="https://cdn.cuiqingcai.com/z8xjy.jpg" srcset="/Blogs/img/loading.gif" lazyload alt="拖曳后页面"></p>
<p>更多的动作链操作可以参考官方文档的动作链介绍：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains%E3%80%82">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains。</a></p>
<h2 id="8-执行-JavaScript"><a href="#8-执行-JavaScript" class="headerlink" title="8. 执行 JavaScript"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#8-%E6%89%A7%E8%A1%8C-JavaScript" title="8. 执行 JavaScript"></a>8. 执行 JavaScript</h2><p>对于某些操作，Selenium API 并没有提供。比如，下拉进度条，它可以直接模拟运行 JavaScript，此时使用 <code>execute_script</code> 方法即可实现，代码如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.zhihu.com/explore">https://www.zhihu.com/explore</a>‘)  <br>browser.execute_script(‘window.scrollTo(0, document.body.scrollHeight)’)  <br>browser.execute_script(‘alert(“To Bottom”)’)</td>
</tr>
</tbody></table>
<p>这里就利用 <code>execute_script</code> 方法将进度条下拉到最底部，然后弹出 alert 提示框。</p>
<p>所以说有了这个方法，基本上 API 没有提供的所有功能都可以用执行 JavaScript 的方式来实现了。</p>
<h2 id="9-获取节点信息"><a href="#9-获取节点信息" class="headerlink" title="9. 获取节点信息"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#9-%E8%8E%B7%E5%8F%96%E8%8A%82%E7%82%B9%E4%BF%A1%E6%81%AF" title="9. 获取节点信息"></a>9. 获取节点信息</h2><p>前面说过，通过 <code>page_source</code> 属性可以获取网页的源代码，接着就可以使用解析库（如正则表达式、Beautiful Soup、pyquery 等）来提取信息了。</p>
<p>不过，既然 Selenium 已经提供了选择节点的方法，返回的是 <code>WebElement</code> 类型，那么它也有相关的方法和属性来直接提取节点信息，如属性、文本等。这样的话，我们就可以不用通过解析源代码来提取信息了，非常方便。</p>
<p>接下来，我们就来看看怎样获取节点信息吧。</p>
<h3 id="获取属性"><a href="#获取属性" class="headerlink" title="获取属性"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#%E8%8E%B7%E5%8F%96%E5%B1%9E%E6%80%A7" title="获取属性"></a>获取属性</h3><p>我们可以使用 <code>get_attribute</code> 方法来获取节点的属性，但是其前提是先选中这个节点，示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>url &#x3D; ‘<a target="_blank" rel="noopener" href="https://spa2.scrape.center/">https://spa2.scrape.center/</a>‘  <br>browser.get(url)  <br>logo &#x3D; browser.find_element_by_class_name(‘logo-image’)  <br>print(logo)  <br>print(logo.get_attribute(‘src’))</td>
</tr>
</tbody></table>
<p>运行之后，程序便会驱动浏览器打开该页面，然后获取 <code>class</code> 为 <code>logo-image</code> 的节点，最后打印出它的 <code>src</code>。</p>
<p>控制台的输出结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”7f4745d35a104759239b53f68a6f27d0”, element&#x3D;”cd7c72b4-4920-47ed-91c5-ea06601dc509”)&gt;  <br><a target="_blank" rel="noopener" href="https://spa2.scrape.center/img/logo.a508a8f0.png">https://spa2.scrape.center/img/logo.a508a8f0.png</a></td>
</tr>
</tbody></table>
<p>通过 <code>get_attribute</code> 方法，然后传入想要获取的属性名，就可以得到它的值了。</p>
<h3 id="获取文本值"><a href="#获取文本值" class="headerlink" title="获取文本值"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#%E8%8E%B7%E5%8F%96%E6%96%87%E6%9C%AC%E5%80%BC" title="获取文本值"></a>获取文本值</h3><p>每个 <code>WebElement</code> 节点都有 <code>text</code> 属性，直接调用这个属性就可以得到节点内部的文本信息，这相当于 pyquery 的 <code>text</code> 方法，示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>url &#x3D; ‘<a target="_blank" rel="noopener" href="https://spa2.scrape.center/">https://spa2.scrape.center/</a>‘  <br>browser.get(url)  <br>input &#x3D; browser.find_element_by_class_name(‘logo-title’)  <br>print(input.text)</td>
</tr>
</tbody></table>
<p>这里依然先打开页面，然后获取 <code>class</code> 为 <code>logo-title</code> 这个节点，再将其文本值打印出来。</p>
<p>控制台的输出结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>Scrape</td>
</tr>
</tbody></table>
<h3 id="获取-ID、位置、标签名和大小"><a href="#获取-ID、位置、标签名和大小" class="headerlink" title="获取 ID、位置、标签名和大小"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#%E8%8E%B7%E5%8F%96-ID%E3%80%81%E4%BD%8D%E7%BD%AE%E3%80%81%E6%A0%87%E7%AD%BE%E5%90%8D%E5%92%8C%E5%A4%A7%E5%B0%8F" title="获取 ID、位置、标签名和大小"></a>获取 ID、位置、标签名和大小</h3><p>另外，<code>WebElement</code> 节点还有一些其他属性，比如 <code>id</code> 属性可以获取节点 ID，<code>location</code> 属性可以获取该节点在页面中的相对位置，<code>tag_name</code> 属性可以获取标签名称，<code>size</code> 属性可以获取节点的大小，也就是宽高，这些属性有时候还是很有用的。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>url &#x3D; ‘<a target="_blank" rel="noopener" href="https://spa2.scrape.center/">https://spa2.scrape.center/</a>‘  <br>browser.get(url)  <br>input &#x3D; browser.find_element_by_class_name(‘logo-title’)  <br>print(input.id)  <br>print(input.location)  <br>print(input.tag_name)  <br>print(input.size)</td>
</tr>
</tbody></table>
<p>这里首先获得 <code>class</code> 为 <code>logo-title</code> 这个节点，然后调用其 <code>id</code>、<code>location</code>、<code>tag_name</code>、<code>size</code> 属性来获取对应的属性值。</p>
<h2 id="10-切换-Frame"><a href="#10-切换-Frame" class="headerlink" title="10. 切换 Frame"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#10-%E5%88%87%E6%8D%A2-Frame" title="10. 切换 Frame"></a>10. 切换 Frame</h2><p>我们知道网页中有一种节点叫作 iframe，也就是子 Frame，相当于页面的子页面，它的结构和外部网页的结构完全一致。Selenium 打开页面后，它默认是在父级 Frame 里面操作，而此时如果页面中还有子 Frame，它是不能获取到子 Frame 里面的节点的。这时就需要使用 <code>switch_to.frame</code> 方法来切换 Frame。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>import time  <br>from selenium import webdriver  <br>from selenium.common.exceptions import NoSuchElementException  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>url &#x3D; ‘<a target="_blank" rel="noopener" href="http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable">http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable</a>‘  <br>browser.get(url)  <br>browser.switch_to.frame(‘iframeResult’)  <br>try:  <br>    logo &#x3D; browser.find_element_by_class_name(‘logo’)  <br>except NoSuchElementException:  <br>    print(‘NO LOGO’)  <br>browser.switch_to.parent_frame()  <br>logo &#x3D; browser.find_element_by_class_name(‘logo’)  <br>print(logo)  <br>print(logo.text)</td>
</tr>
</tbody></table>
<p>控制台输出结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>NO LOGO  <br>&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”4bb8ac03ced4ecbdefef03ffdc0e4ccd”, element&#x3D;”0.13792611320464965-2”)&gt;  <br>RUNOOB.COM</td>
</tr>
</tbody></table>
<p>这里还是以前面演示动作链操作的网页为实例，首先通过 <code>switch_to.frame</code> 方法切换到子 Frame 里面，然后尝试获取子 Frame 里的 logo 节点（这是找不到的），如果找不到的话，就会抛出 <code>NoSuchElementException</code> 异常，异常被捕捉之后，就会输出 <code>NO LOGO</code>。接下来，重新切换回父级 Frame，然后再次重新获取节点，发现此时可以成功获取了。</p>
<p>所以，当页面中包含子 Frame 时，如果想获取子 Frame 中的节点，需要先调用 <code>switch_to.frame</code> 方法切换到对应的 Frame，然后再进行操作。</p>
<h2 id="11-延时等待"><a href="#11-延时等待" class="headerlink" title="11. 延时等待"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#11-%E5%BB%B6%E6%97%B6%E7%AD%89%E5%BE%85" title="11. 延时等待"></a>11. 延时等待</h2><p>在 Selenium 中，<code>get</code> 方法会在网页框架加载结束后结束执行，此时如果获取 <code>page_source</code>，可能并不是浏览器完全加载完成的页面，如果某些页面有额外的 Ajax 请求，我们在网页源代码中也不一定能成功获取到。所以，这里需要延时等待一定时间，确保节点已经加载出来。</p>
<p>这里等待方式有两种：一种是隐式等待，一种是显式等待。</p>
<h3 id="隐式等待"><a href="#隐式等待" class="headerlink" title="隐式等待"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#%E9%9A%90%E5%BC%8F%E7%AD%89%E5%BE%85" title="隐式等待"></a>隐式等待</h3><p>当使用隐式等待执行测试的时候，如果 Selenium 没有在 DOM 中找到节点，将继续等待，超出设定时间后，则抛出找不到节点的异常。换句话说，当查找节点而节点并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是 0。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.implicitly_wait(10)  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://spa2.scrape.center/">https://spa2.scrape.center/</a>‘)  <br>input &#x3D; browser.find_element_by_class_name(‘logo-image’)  <br>print(input)</td>
</tr>
</tbody></table>
<p>这里我们用 <code>implicitly_wait</code> 方法实现了隐式等待。</p>
<h3 id="显式等待"><a href="#显式等待" class="headerlink" title="显式等待"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#%E6%98%BE%E5%BC%8F%E7%AD%89%E5%BE%85" title="显式等待"></a>显式等待</h3><p>隐式等待的效果其实并没有那么好，因为我们只规定了一个固定时间，而页面的加载时间会受到网络条件的影响。</p>
<p>这里还有一种更合适的显式等待方法，它指定要查找的节点，然后指定一个最长等待时间。如果在规定时间内加载出来了这个节点，就返回查找的节点；如果到了规定时间依然没有加载出该节点，则抛出超时异常。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>from selenium.webdriver.common.by import By  <br>from selenium.webdriver.support.ui import WebDriverWait  <br>from selenium.webdriver.support import expected_conditions as EC  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com/</a>‘)  <br>wait &#x3D; WebDriverWait(browser, 10)  <br>input &#x3D; wait.until(EC.presence_of_element_located((By.ID, ‘q’)))  <br>button &#x3D; wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, ‘.btn-search’)))  <br>print(input, button)</td>
</tr>
</tbody></table>
<p>这里首先引入 <code>WebDriverWait</code> 这个对象，指定最长等待时间，然后调用它的 <code>until</code>方法，传入等待条件 <code>expected_conditions</code>。比如，这里传入了 <code>presence_of_element_located</code> 这个条件，代表节点出现的意思，其参数是节点的定位元组，也就是 ID 为 <code>q</code> 的节点搜索框。</p>
<p>这样可以做到的效果就是，在 10 秒内如果 ID 为 <code>q</code> 的节点（即搜索框）成功加载出来，就返回该节点；如果超过 10 秒还没有加载出来，就抛出异常。</p>
<p>对于按钮，可以更改一下等待条件，比如改为 <code>element_to_be_clickable</code>，也就是可点击，所以查找按钮时查找 CSS 选择器为 <code>.btn-search</code> 的按钮，如果 10 秒内它是可点击的，也就是成功加载出来了，就返回这个按钮节点；如果超过 10 秒还不可点击，也就是没有加载出来，就抛出异常。</p>
<p>运行代码，在网速较佳的情况下是可以成功加载出来的。</p>
<p>控制台的输出如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”07dd2fbc2d5b1ce40e82b9754aba8fa8”, element&#x3D;”0.5642646294074107-1”)&gt;  <br>&lt;selenium.webdriver.remote.webelement.WebElement (session&#x3D;”07dd2fbc2d5b1ce40e82b9754aba8fa8”, element&#x3D;”0.5642646294074107-2”)&gt;</td>
</tr>
</tbody></table>
<p>可以看到，控制台成功输出了两个节点，它们都是 <code>WebElement</code> 类型。</p>
<p>如果网络有问题，10 秒内没有成功加载，那就抛出 <code>TimeoutException</code> 异常，此时控制台的输出如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>TimeoutException Traceback (most recent call last)  <br><ipython-input-4-f3d73973b223> in <module>()  <br>      7 browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com/</a>‘)  <br>      8 wait &#x3D; WebDriverWait(browser, 10)  <br>—-&gt; 9 input &#x3D; wait.until(EC.presence_of_element_located((By.ID, ‘q’)))</td>
</tr>
</tbody></table>
<p>关于等待条件，其实还有很多，比如判断标题内容，判断某个节点内是否出现了某文字等。下表列出了所有的等待条件。</p>
<table>
<thead>
<tr>
<th>等待条件</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>title_is</code></td>
<td>标题是某内容</td>
</tr>
<tr>
<td><code>title_contains</code></td>
<td>标题包含某内容</td>
</tr>
<tr>
<td><code>presence_of_element_located</code></td>
<td>节点加载出来，传入定位元组，如 <code>(By.ID, &#39;p&#39;)</code></td>
</tr>
<tr>
<td><code>visibility_of_element_located</code></td>
<td>节点可见，传入定位元组</td>
</tr>
<tr>
<td><code>visibility_of</code></td>
<td>可见，传入节点对象</td>
</tr>
<tr>
<td><code>presence_of_all_elements_located</code></td>
<td>所有节点加载出来</td>
</tr>
<tr>
<td><code>text_to_be_present_in_element</code></td>
<td>某个节点文本包含某文字</td>
</tr>
<tr>
<td><code>text_to_be_present_in_element_value</code></td>
<td>某个节点值包含某文字</td>
</tr>
<tr>
<td><code>frame_to_be_available_and_switch_to_it frame</code></td>
<td>加载并切换</td>
</tr>
<tr>
<td><code>invisibility_of_element_located</code></td>
<td>节点不可见</td>
</tr>
<tr>
<td><code>element_to_be_clickable</code></td>
<td>节点可点击</td>
</tr>
<tr>
<td><code>staleness_of</code></td>
<td>判断一个节点是否仍在 DOM，可判断页面是否已经刷新</td>
</tr>
<tr>
<td><code>element_to_be_selected</code></td>
<td>节点可选择，传入节点对象</td>
</tr>
<tr>
<td><code>element_located_to_be_selected</code></td>
<td>节点可选择，传入定位元组</td>
</tr>
<tr>
<td><code>element_selection_state_to_be</code></td>
<td>传入节点对象以及状态，相等返回 <code>True</code>，否则返回 <code>False</code></td>
</tr>
<tr>
<td><code>element_located_selection_state_to_be</code></td>
<td>传入定位元组以及状态，相等返回 <code>True</code>，否则返回 <code>False</code></td>
</tr>
<tr>
<td><code>alert_is_present</code></td>
<td>是否出现 Alert</td>
</tr>
</tbody></table>
<p>更多等待条件的参数及用法介绍可以参考官方文档：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions%E3%80%82">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions。</a></p>
<h2 id="12-前进后退"><a href="#12-前进后退" class="headerlink" title="12. 前进后退"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#12-%E5%89%8D%E8%BF%9B%E5%90%8E%E9%80%80" title="12. 前进后退"></a>12. 前进后退</h2><p>平常使用浏览器时，都有前进和后退功能，Selenium 也可以完成这个操作，它使用 <code>back</code> 方法后退，使用 <code>forward</code> 方法前进。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>import time  <br>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com/</a>‘)  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com/</a>‘)  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.python.org/">https://www.python.org/</a>‘)  <br>browser.back()  <br>time.sleep(1)  <br>browser.forward()  <br>browser.close()</td>
</tr>
</tbody></table>
<p>这里我们连续访问 3 个页面，然后调用 <code>back</code> 方法回到第二个页面，接下来再调用 <code>forward</code> 方法又可以前进到第三个页面。</p>
<h2 id="13-Cookies"><a href="#13-Cookies" class="headerlink" title="13. Cookies"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#13-Cookies" title="13. Cookies"></a>13. Cookies</h2><p>使用 Selenium，还可以方便地对 Cookies 进行操作，例如获取、添加、删除 Cookies 等。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.zhihu.com/explore">https://www.zhihu.com/explore</a>‘)  <br>print(browser.get_cookies())  <br>browser.add_cookie({‘name’: ‘name’, ‘domain’: ‘<a target="_blank" rel="noopener" href="http://www.zhihu.com/">www.zhihu.com</a>‘, ‘value’: ‘germey’})  <br>print(browser.get_cookies())  <br>browser.delete_all_cookies()  <br>print(browser.get_cookies())</td>
</tr>
</tbody></table>
<p>首先，我们访问了知乎。加载完成后，浏览器实际上已经生成 Cookies 了。接着，调用 <code>get_cookies</code> 方法获取所有的 Cookies。然后，我们添加一个 Cookie，这里传入一个字典，有 <code>name</code>、<code>domain</code> 和 <code>value</code> 等内容。接下来，再次获取所有的 Cookies。可以发现，结果就多了这一项新加的 Cookie。最后，调用 <code>delete_all_cookies</code> 方法删除所有的 Cookies。再重新获取，发现结果就为空了。</p>
<p>控制台的输出如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>[{‘secure’: False, ‘value’: ‘“NGM0ZTM5NDAwMWEyNDQwNDk5ODlkZWY3OTkxY2I0NDY&#x3D;|1491604091|236e34290a6f407bfbb517888849ea509ac366d0”‘, ‘domain’: ‘.zhihu.com’, ‘path’: ‘&#x2F;‘, ‘httpOnly’: False, ‘name’: ‘l_cap_id’, ‘expiry’: 1494196091.403418}, …]  <br>[{‘secure’: False, ‘value’: ‘germey’, ‘domain’: ‘.<a target="_blank" rel="noopener" href="http://www.zhihu.com/">www.zhihu.com</a>‘, ‘path’: ‘&#x2F;‘, ‘httpOnly’: False, ‘name’: ‘name’}, {‘secure’: False, ‘value’: ‘“NGM0ZTM5NDAwMWEyNDQwNDk5ODlkZWY3OTkxY2I0NDY&#x3D;|1491604091|236e34290a6f407bfbb517888849ea509ac366d0”‘, ‘domain’: ‘.zhihu.com’, ‘path’: ‘&#x2F;‘, ‘httpOnly’: False, ‘name’: ‘l_cap_id’, ‘expiry’: 1494196091.403418}, …]  <br>[]</td>
</tr>
</tbody></table>
<p>通过以上方法来操作 Cookies 还是非常方便的。</p>
<h2 id="14-选项卡管理"><a href="#14-选项卡管理" class="headerlink" title="14. 选项卡管理"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#14-%E9%80%89%E9%A1%B9%E5%8D%A1%E7%AE%A1%E7%90%86" title="14. 选项卡管理"></a>14. 选项卡管理</h2><p>在访问网页的时候，会开启一个个选项卡。在 Selenium 中，我们也可以对选项卡进行操作。示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>import time  <br>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com</a>‘)  <br>browser.execute_script(‘window.open()’)  <br>print(browser.window_handles)  <br>browser.switch_to.window(browser.window_handles[1])  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.taobao.com/">https://www.taobao.com</a>‘)  <br>time.sleep(1)  <br>browser.switch_to.window(browser.window_handles[0])  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://python.org/">https://python.org</a>‘)</td>
</tr>
</tbody></table>
<p>控制台的输出如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>[‘CDwindow-4f58e3a7-7167-4587-bedf-9cd8c867f435’, ‘CDwindow-6e05f076-6d77-453a-a36c-32baacc447df’]</td>
</tr>
</tbody></table>
<p>这里首先访问了百度，然后调用了 <code>execute_script</code> 方法，这里传入 <code>window.open</code>这个 JavaScript 语句新开启一个选项卡。接下来，我们想切换到该选项卡。这里调用 <code>window_handles</code> 属性获取当前开启的所有选项卡，返回的是选项卡的代号列表。要想切换选项卡，只需要调用 <code>switch_to.window</code> 方法即可，其中参数是选项卡的代号。这里我们将第二个选项卡代号传入，即跳转到第二个选项卡，接下来在第二个选项卡下打开一个新页面，然后切换回第一个选项卡重新调用 <code>switch_to.window</code> 方法，再执行其他操作即可。</p>
<h2 id="15-异常处理"><a href="#15-异常处理" class="headerlink" title="15. 异常处理"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#15-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86" title="15. 异常处理"></a>15. 异常处理</h2><p>在使用 Selenium 的过程中，难免会遇到一些异常，例如超时、节点未找到等错误，一旦出现此类错误，程序便不会继续运行了。这里我们可以使用 <code>try except</code> 语句来捕获各种异常。</p>
<p>首先，演示一下节点未找到的异常，示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com</a>‘)  <br>browser.find_element_by_id(‘hello’)</td>
</tr>
</tbody></table>
<p>这里首先打开百度页面，然后尝试选择一个并不存在的节点，此时就会遇到异常。</p>
<p>运行之后控制台的输出如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>NoSuchElementException Traceback (most recent call last)  <br><ipython-input-23-978945848a1b> in <module>()  <br>      3 browser &#x3D; webdriver.Chrome()  <br>      4 browser.get(‘<a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com</a>‘)  <br>—-&gt; 5 browser.find_element_by_id(‘hello’)</td>
</tr>
</tbody></table>
<p>可以看到，这里抛出了 <code>NoSuchElementException</code> 异常，这通常是节点未找到的异常。为了防止程序遇到异常而中断，我们需要捕获这些异常，示例如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>from selenium.common.exceptions import TimeoutException, NoSuchElementException  <br>  <br>browser &#x3D; webdriver.Chrome()  <br>try:  <br>    browser.get(‘<a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com</a>‘)  <br>except TimeoutException:  <br>    print(‘Time Out’)  <br>try:  <br>    browser.find_element_by_id(‘hello’)  <br>except NoSuchElementException:  <br>    print(‘No Element’)  <br>finally:  <br>    browser.close()</td>
</tr>
</tbody></table>
<p>这里我们使用 <code>try except</code> 来捕获各类异常。比如，我们对 <code>find_element_by_id</code>查找节点的方法捕获 <code>NoSuchElementException</code> 异常，这样一旦出现这样的错误，就进行异常处理，程序也不会中断了。</p>
<p>控制台的输出如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>No Element</td>
</tr>
</tbody></table>
<p>关于更多的异常类，可以参考官方文档：：<a target="_blank" rel="noopener" href="http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions%E3%80%82">http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions。</a></p>
<h2 id="16-反屏蔽"><a href="#16-反屏蔽" class="headerlink" title="16. 反屏蔽"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#16-%E5%8F%8D%E5%B1%8F%E8%94%BD" title="16. 反屏蔽"></a>16. 反屏蔽</h2><p>现在很多网站都加上了对 Selenium 的检测，来防止一些爬虫的恶意爬取。即如果检测到有人在使用 Selenium 打开浏览器，那就直接屏蔽。</p>
<p>在大多数情况下，检测的基本原理是检测当前浏览器窗口下的 <code>window.navigator</code> 对象是否包含 <code>webdriver</code> 这个属性。因为在正常使用浏览器的情况下，这个属性是 <code>undefined</code>，然而一旦我们使用了 Selenium，Selenium 会给 <code>window.navigator</code> 设置 <code>webdriver</code> 属性。很多网站就通过 JavaScript 判断如果 <code>webdriver</code> 属性存在，那就直接屏蔽。</p>
<p>这边有一个典型的案例网站：<a target="_blank" rel="noopener" href="https://antispider1.scrape.center/%EF%BC%8C%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E5%B0%B1%E4%BD%BF%E7%94%A8%E4%BA%86%E4%B8%8A%E8%BF%B0%E5%8E%9F%E7%90%86%E5%AE%9E%E7%8E%B0%E4%BA%86">https://antispider1.scrape.center/，这个网站就使用了上述原理实现了</a> WebDriver 的检测，如果使用 Selenium 直接爬取的话，那就会返回如图所示的页面。</p>
<p><img src="https://cdn.cuiqingcai.com/l13mw.png" srcset="/Blogs/img/loading.gif" lazyload alt="image-20210705014022028"></p>
<p>这时候我们可能想到直接使用 JavaScript 语句把这个 <code>webdriver</code> 属性置空，比如通过调用 <code>execute_script</code> 方法来执行如下代码：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>Object.defineProperty(navigator, “webdriver”, { get: () &#x3D;&gt; undefined });</td>
</tr>
</tbody></table>
<p>这行 JavaScript 语句的确可以把 <code>webdriver</code> 属性置空，但是 <code>execute_script</code> 调用这行 JavaScript 语句实际上是在页面加载完毕之后才执行的，执行太晚了，网站早在最初页面渲染之前就已经对 <code>webdriver</code> 属性进行了检测，所以用上述方法并不能达到效果。</p>
<p>在 Selenium 中，我们可以使用 CDP（即 Chrome Devtools-Protocol，Chrome 开发工具协议）来解决这个问题，通过它我们可以实现在每个页面刚加载的时候执行 JavaScript 代码，执行的 CDP 方法叫作 <code>Page.addScriptToEvaluateOnNewDocument</code>，然后传入上文的 JavaScript 代码即可，这样我们就可以在每次页面加载之前将 <code>webdriver</code> 属性置空了。另外，我们还可以加入几个选项来隐藏 WebDriver 提示条和自动化扩展信息，代码实现如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>from selenium.webdriver import ChromeOptions  <br>  <br>option &#x3D; ChromeOptions()  <br>option.add_experimental_option(‘excludeSwitches’, [‘enable-automation’])  <br>option.add_experimental_option(‘useAutomationExtension’, False)  <br>browser &#x3D; webdriver.Chrome(options&#x3D;option)  <br>browser.execute_cdp_cmd(‘Page.addScriptToEvaluateOnNewDocument’, {  <br>    ‘source’: ‘Object.defineProperty(navigator, “webdriver”, {get: () &#x3D;&gt; undefined})’  <br>})  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://antispider1.scrape.center/">https://antispider1.scrape.center/</a>‘)</td>
</tr>
</tbody></table>
<p>这样整个页面就能被加载出来了，如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/tywxa.png" srcset="/Blogs/img/loading.gif" lazyload></p>
<p>对于大多数情况，以上方法均可以实现 Selenium 反屏蔽。但对于一些特殊网站，如果它有更多的 WebDriver 特征检测，可能需要具体排查。</p>
<h2 id="17-无头模式"><a href="#17-无头模式" class="headerlink" title="17. 无头模式"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#17-%E6%97%A0%E5%A4%B4%E6%A8%A1%E5%BC%8F" title="17. 无头模式"></a>17. 无头模式</h2><p>我们可以观察到，上面的案例在运行的时候，总会弹出一个浏览器窗口，虽然有助于观察页面爬取状况，但在有时候窗口弹来弹去也会形成一些干扰。</p>
<p>Chrome 浏览器从 60 版本已经支持了无头模式，即 Headless。无头模式在运行的时候不会再弹出浏览器窗口，减少了干扰，而且它减少了一些资源的加载，如图片等，所以也在一定程度上节省了资源加载时间和网络带宽。</p>
<p>我们可以借助于 ChromeOptions 来开启 Chrome Headless 模式，代码实现如下：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>from selenium import webdriver  <br>from selenium.webdriver import ChromeOptions  <br>  <br>option &#x3D; ChromeOptions()  <br>option.add_argument(‘–headless’)  <br>browser &#x3D; webdriver.Chrome(options&#x3D;option)  <br>browser.set_window_size(1366, 768)  <br>browser.get(‘<a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com</a>‘)  <br>browser.get_screenshot_as_file(‘preview.png’)</td>
</tr>
</tbody></table>
<p>这里我们通过 ChromeOptions 的 <code>add_argument</code> 方法添加了一个参数 <code>--headless</code>，开启了无头模式。在无头模式下，我们最好设置一下窗口的大小，接着打开页面，最后我们调用 <code>get_screenshot_as_file</code> 方法输出了页面的截图。</p>
<p>运行代码之后，我们发现 Chrome 窗口就不会再弹出来了，代码依然正常运行，最后输出的页面如图所示。</p>
<p><img src="https://cdn.cuiqingcai.com/8h0oa.png" srcset="/Blogs/img/loading.gif" lazyload alt="输出的页面"></p>
<p>这样我们就在无头模式下完成了页面的抓取和截图操作。</p>
<h2 id="18-总结"><a href="#18-总结" class="headerlink" title="18. 总结"></a><a target="_blank" rel="noopener" href="https://cuiqingcai.com/202261.html#18-%E6%80%BB%E7%BB%93" title="18. 总结"></a>18. 总结</h2><p>现在，我们基本上对 Selenium 的常规用法有了大体的了解。使用 Selenium，处理 JavaScript 渲染的页面不再是难事，后面我们会用一个实例来演示 Selenium 爬取网站的流程。</p>
<p>本节代码：<a target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/SeleniumTest%E3%80%82">https://github.com/Python3WebSpider/SeleniumTest。</a></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/Blogs/categories/%E7%A8%8B%E5%BA%8F/" class="category-chain-item">程序</a>
  
  
    <span>></span>
    
  <a href="/Blogs/categories/%E7%A8%8B%E5%BA%8F/03%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80/" class="category-chain-item">03高级语言</a>
  
  
    <span>></span>
    
  <a href="/Blogs/categories/%E7%A8%8B%E5%BA%8F/03%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80/Python/" class="category-chain-item">Python</a>
  
  
    <span>></span>
    
  <a href="/Blogs/categories/%E7%A8%8B%E5%BA%8F/03%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80/Python/python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/" class="category-chain-item">python爬虫学习</a>
  
  

  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/Blogs/tags/Ajax%E5%86%85%E5%AE%B9%E7%88%AC%E5%8F%96/" class="print-no-link">#Ajax内容爬取</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Ajax内容爬取</div>
      <div>http://mavericreate.top/Blogs/2025/08/28/Ajax内容爬取/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>唐浩天</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年8月28日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/Blogs/2025/08/28/C%E8%AF%AD%E8%A8%80%E4%BB%A3%E7%A0%81%E9%9B%86/" title="C语言代码集">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">C语言代码集</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/Blogs/2025/08/28/C%E8%AF%AD%E8%A8%80%E6%8C%87%E9%92%88/" title="C语言指针">
                        <span class="hidden-mobile">C语言指针</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/Blogs/js/events.js" ></script>
<script  src="/Blogs/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/Blogs/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/Blogs/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/Blogs/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
